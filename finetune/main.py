import os
import glob
import json
import re

# This script builds fine-tuning training data from the Octoterra test cases.
# It creates the prompt and response pairs, where the prompt is a description of the Terraform configuration, generated by Azure OpenAI,
# The response is the Terraform used by the test case.

AZURE_OPENAI_ENDPOINT = os.getenv("AISERVICES_ENDPOINT") + "openai/deployments/gpt-4.1-mini/chat/completions?api-version=2024-02-15-preview"
AZURE_OPENAI_API_KEY = os.getenv("AISERVICES_KEY")
SCHEMA_PATH = "schema.json"
BASE_DIR = "../test/terraform"
# These are bolierplate files that don't add any unique value to the training data.
EXCLUDE_FILES = {"config.tf", "provider.tf", "space.tf", "provider_vars.tf"}

def find_space_population_dirs(base_dir):
    return [os.path.join(dp, "space_population") for dp, dn, fn in os.walk(base_dir) if "space_population" in dn]

def get_tf_files(space_pop_dir):
    return [
        f for f in glob.glob(os.path.join(space_pop_dir, "*.tf"))
        if os.path.basename(f) not in EXCLUDE_FILES
    ]

def extract_resource_names(tf_content):
    pattern = r'(resource|data)\s+"([^"]+)"\s+"([^"]+)"'
    return set(match.group(2) for match in re.finditer(pattern, tf_content))

def load_schema(schema_path):
    with open(schema_path, "r") as f:
        return json.load(f)

def filter_resource_schemas(resource_names, schema):
    resource_schemas = {k: v for k, v in schema.get('provider_schemas', {}).get('registry.terraform.io/octopusdeploy/octopusdeploy', {}).get('resource_schemas', {}).items() if k in resource_names}
    data_source_schemas = {k: v for k, v in schema.get('provider_schemas', {}).get('registry.terraform.io/octopusdeploy/octopusdeploy', {}).get('data_source_schemas', {}).items() if k in resource_names}
    return {**resource_schemas, **data_source_schemas}

def query_azure_openai(tf_contents, schema_json):
    headers = {
        "api-key": AZURE_OPENAI_API_KEY,
        "Content-Type": "application/json"
    }
    user_prompt = (
        "Describe the terraform configuration in the form of a prompt to recreate the contents. "
        "When describing the terraform resource to be created, describe the resource using the description from the resource schema.\n"
        "When defining the attributes of the terraform configuration, describe the attribute using the description from the resource schema.\n"
        "For example:\n"
        "Create a data source \"octopusdeploy_feeds\" named \"built_in_feed\" to provide information about existing feeds with attributes: feed_type set to \"BuiltIn\" to filter the feed type, skip set to 0 to skip zero items in the response, and take set to 1 to take one item in the response.\n"
        "Terraform files:\n"
        f"{tf_contents}\n\n"
        "Relevant resource schema:\n"
        f"{json.dumps(schema_json, indent=2)}"
    )
    payload = {
        "messages": [
            {"role": "system", "content": "You are an expert in reading and describing Terraform configuration files."},
            {"role": "system", "content": "You must provide a concise answer."},
            {"role": "system", "content": "You will be penalized for providing an introductory sentence that describes the answer."},
            {"role": "system", "content": "You will be penalized for providing an answer in a conversational tone."},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.2,
        "max_tokens": 1024
    }
    import requests
    response = requests.post(AZURE_OPENAI_ENDPOINT, headers=headers, json=payload)
    response.raise_for_status()
    result = response.json()
    return result["choices"][0]["message"]["content"]

def filter_attributes_descriptions(obj):
    if isinstance(obj, dict):
        new_obj = {}
        for k, v in obj.items():
            if k == "attributes" and isinstance(v, dict):
                # Only keep the 'description' key in each nested dict
                new_obj[k] = {attr: {"description": attr_val.get("description")} for attr, attr_val in v.items() if isinstance(attr_val, dict) and "description" in attr_val}
            else:
                new_obj[k] = filter_attributes_descriptions(v)
        return new_obj
    elif isinstance(obj, list):
        return [filter_attributes_descriptions(item) for item in obj]
    else:
        return obj

def main():
    schema = load_schema(SCHEMA_PATH)
    space_pop_dirs = find_space_population_dirs(BASE_DIR)

    count = 2

    for space_pop_dir in space_pop_dirs:
        tf_files = get_tf_files(space_pop_dir)
        if not tf_files:
            continue
        tf_contents = ""
        all_resource_names = set()
        for tf_file in tf_files:
            with open(tf_file, "r") as f:
                content = f.read()
                tf_contents += f"{content}\n"
                all_resource_names.update(extract_resource_names(content))

        tf_contents = "\n".join([line for line in tf_contents.splitlines() if not line.startswith("#")])  # Remove comments

        relevant_schemas = filter_resource_schemas(all_resource_names, schema)
        filtered_schemas = filter_attributes_descriptions(relevant_schemas)
        prompt_response = query_azure_openai(tf_contents, filtered_schemas)
        output_blob = {
            "messages": [
                {"role": "system", "content": "You are an expert in generating Octopus Deploy Terraform configurations."},
                {"role": "user", "content": prompt_response},
                {"role": "assistant", "content": tf_contents}
            ]
        }
        out_path = "octopus_ai_prompt_response.jsonl"
        with open(out_path, "a") as f:
            item = json.dumps(output_blob, separators=(',', ':'))
            f.write(item + "\n")
        print(f"Saved prompt response to {out_path}")

        # This is used to limit the number of test cases processed for debugging purposes.
        # count -= 1
        # if count <= 0:
        #     break

if __name__ == "__main__":
    main()